{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGQcfu3r9rdX"
   },
   "source": [
    "# Mini-Projet `MNIST`\n",
    "Auteurs: *Emilie GALLAND*, *Léo BRENDLE*, *Fouad AFANE*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataset `MNIST` est un incoutournable du machine learning. Ce problème de classification de chiffres écrits à la main a joué un rôle historique important (lecture automatique des codes postaux aux Etats-Unis). Il a donné lieu à de nombreuses études comparatives. On pourra consulter par exemple [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "**Conseils:**\n",
    "- on trouve sur internet de nombreuses études de ce jeux de données classiques; on pourra bien sûr s’en inspirer, mais tout copié-collé abusif est proscrit et sera sanctionné, de même que le recours abusif à l'IA ou la copie entre binômes.\n",
    "- la rédaction (description de la méthodologie) et l'interprétation des résultats rentreront fortement en compte dans l'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des librairies et des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "col_names = ['Y'] + [f'X{i}' for i in range(1, 785)]\n",
    "mnist_train = pd.read_csv(\"mnist_train.csv\", sep=\",\", names=col_names, header=None)\n",
    "mnist_test = pd.read_csv(\"mnist_test.csv\", sep=\",\", names=col_names, header=None)\n",
    "mnist_train['Y'] = mnist_train['Y'].astype('category')\n",
    "mnist_test['Y'] = mnist_test['Y'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage de la premiere ligne sous forme d'image et label\n",
    "\n",
    "M = mnist_train.iloc[0, 1:].to_numpy()   # vecteur de 784 pixels\n",
    "M = M.reshape((28, 28))                  # transformation en matrice 28x28\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(M, cmap=\"gray\", interpolation=\"nearest\")\n",
    "plt.title(f\"Chiffre {mnist_train.iloc[0, 0]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des 9 premieres ligne sous forme d'image et label\n",
    "\n",
    "for i in range(9):\n",
    "    # Extraction de l'image\n",
    "    M = mnist_train.iloc[i, 1:].to_numpy().reshape((28, 28))\n",
    " \n",
    "    # Ajout du subplot\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(M, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.title(f\"Chiffre {mnist_train.iloc[i, 0]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tâches à effectuer\n",
    "Comparer les différentes méthodes vues en cours sur le jeu de données `MNIST`. On entrainera les méthodes sur l'échantillon train et évaluera leur performance sur l'échantillon test. Lorsque cela sera pertinent, on ajustera les hyperparamètres de la méthode par validation croisée à 10 couches sur l'échantillon train. Dans cette tâche de classification multitype à 10 classes, on pourra utiliser directement un classifieur multitype ou bien un classifieur binaire avec une approche  One Versus All.\n",
    "On pourra s'inspirer du plan de travail suivant, sans que cela ne soit restrictif.\n",
    "\n",
    "**Plan de travail**\n",
    "1. Décrire les jeu de données. En particulier nombre d'exemples en apprentissage et en test; proportion de chaque classe dans les deux échantillons.\n",
    "2. Appliquer la méthode des k plus proches voisins après centrage et réduction des données.\n",
    "3. Appliquer la méthode de régression logistique.\n",
    "4. Appliquer la méthode d'analyse discriminante linéaire.\n",
    "5. Appliquer la méthode Random Forest en optimisant `max_features`.\n",
    "6. Appliquer la méthode Support Vector Machine avec noyau gaussien en optimisant `gamma`.\n",
    "7. Appliquer l'algorithme XGBoost (charger la librairie) ou bien l'algorithme Gradient Boosting de scikitlearn.\n",
    "8. Représenter sur un graphique le taux d'erreur pour chacune des méthodes et commenter.éthodes et conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données MNIST (Modified National Institute of Standards and Technology) est une grande base d'images représentant des chiffres écrits à la main. Il est souvent utilisé en intelligence artificielle pour tester les performances de modèles, pour des tâches comme le débruitage d'images ou la vision par ordinateur par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mnist_train), np.shape(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist_train est un data frame de taille 60000 $\\times$ 785. Les variables sont des variables quantitatives avec Y la vraie valeur du chiffre écrit et les variables X, sont des variables qui représentent les intensités des pixels (entre 0 et 1, 0 : noir, 1 : blanc). Chaque ligne représente donc une image en noir et blanc au format 28x28 pixels, ainsi que le chiffre manuscrit qui est représenté.\n",
    "\n",
    "De même mnist_test est un data frame de taille 10000 $\\times$ 785. On a donc environ 14% des valeurs qui sont dans le jeu test afin d'évaluer la qualité des modèles entrainés sur mnist_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes des k plus proches voisins\n",
    "\n",
    "Dans cette partie, on souhaite appliquer la méthode des k plus proches voisins . \\\n",
    "Ce modèle prédit la classe majoritaire pour les k proches voisins, c'est à dire:\n",
    "$\n",
    "\\hat{y} = \\arg\\max_{C} \\operatorname{card}\\left\\{ i \\mid Y_i = C,\\, X_i \\in N_k(x) \\right\\}\n",
    "$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Méthode des k plus proches voisins\n",
    "\n",
    "#on commence par centré et réduire les variables X\n",
    "scaler = StandardScaler()\n",
    "X_scaled_train = scaler.fit_transform(mnist_train.iloc[:,1:])\n",
    "X_scaled_test = scaler.fit_transform(mnist_test.iloc[:,1:])\n",
    "Y_train = mnist_train.iloc[:,0]\n",
    "Y_test = mnist_test.iloc[:,0]\n",
    "\n",
    "#On applique la méthode des K plus proches voisins avec une grille d'hyperparamètres\n",
    "param_grid = {'n_neighbors' : range(1,5)}\n",
    "models_knn = GridSearchCV(KNeighborsClassifier(), param_grid, n_jobs=-1).fit(X_scaled_train, Y_train)\n",
    "cv_results = pd.DataFrame(models_knn.cv_results_)\n",
    "cv_results.head()\n",
    "best_model_knn = models_knn.best_estimator_\n",
    "err_test_knn = mean_squared_error(best_model_knn.predict(X_scaled_test), Y_test)\n",
    "err_train_knn = mean_squared_error(best_model_knn.predict(X_scaled_test), Y_train)\n",
    "print(f\"L'erreur quadratique moyenne du modèle des plus proches voisins sur l'échantillon d'apprentissage est de {err_train_knn:.3f} et de {err_test_knn:.3f} sur l'échantillon test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de régression logistique\n",
    "\n",
    "On applique un modèle de régression logistique.\n",
    "Le modèle peut s'écrire :  \n",
    "$\\hat{y} = \\arg\\max_{C} \\mathbb{P}(Y = C \\mid X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modèles de régression logistique\n",
    "model_reg_log = LogisticRegression(max_iter = 100, solver = 'newton-cg')\n",
    "model_reg_log.fit(X_scaled_train, Y_train)\n",
    "x0 = X_scaled_test[0,:].reshape(1,-1)\n",
    "y0 = model_reg_log.predict(x0)\n",
    "print(f\"Le nombre prédit en x0 est y0 = {y0.item():.3f} or y = {Y_test[0]}\")\n",
    "y_pred_test = model_reg_log.predict(X_scaled_test)\n",
    "y_pred_train = model_reg_log.predict(X_scaled_train)\n",
    "err_test_log = mean_squared_error(y_pred_test, Y_test)\n",
    "err_train_log = mean_squared_error(y_pred_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L'erreur quadratique moyenne du modèle de régression logistique sur l'échantillon d'apprentissage est de {err_train_log:.3f} et de {err_test_log:.3f} sur l'échantillon test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse discriminante linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_scaled_train, Y_train)\n",
    "print(f\"Le nombre prédit en x0 est Y0 = {LDA.predict(x0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) à noyau gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 969242,
     "sourceId": 1639397,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30028,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
