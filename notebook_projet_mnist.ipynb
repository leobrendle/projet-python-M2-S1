{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGQcfu3r9rdX"
   },
   "source": [
    "# Mini-Projet `MNIST`\n",
    "Auteurs: *Emilie GALLAND*, *Léo BRENDLE*, *Fouad AFANE*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données MNIST est un classique du machine learning. Il contient des images de chiffres manuscrits (de 0 à 9) utilisées pour des tâches de reconnaissance automatique. Ce jeu de données comprend 60 000 exemples pour l’apprentissage et 10 000 pour le test. Chaque image fait 28×28 pixels, soit 784 variables par observation.\n",
    "\n",
    "L’objectif de ce travail est de comparer plusieurs méthodes de classification sur ce jeu de données. Les modèles seront entraînés sur l’échantillon train et testés sur l’échantillon test. Lorsque ce sera utile, les hyperparamètres seront ajustés par validation croisée à 10 plis.\n",
    "On utilisera des méthodes linéaires et non linéaires, en mode multiclasse direct ou avec une approche One-Versus-All."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan**\n",
    "1. Description du jeu de données\n",
    "2. k plus proches voisins (k-NN)\n",
    "3. Régression logistique\n",
    "4. Analyse discriminante linéaire (LDA)\n",
    "5. Random Forest\n",
    "6. SVM à noyau gaussien\n",
    "7. XGBoost\n",
    "8. Comparaison et conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies et des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des librairies et des données\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "col_names = ['Y'] + [f'X{i}' for i in range(1, 785)]\n",
    "mnist_train = pd.read_csv(\"mnist_train.csv\", sep=\",\", names=col_names, header=None)\n",
    "mnist_test = pd.read_csv(\"mnist_test.csv\", sep=\",\", names=col_names, header=None)\n",
    "mnist_train['Y'] = mnist_train['Y'].astype('category')\n",
    "mnist_test['Y'] = mnist_test['Y'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données MNIST (Modified National Institute of Standards and Technology) est une grande base d'images représentant des chiffres écrits à la main. Il est souvent utilisé en intelligence artificielle pour tester les performances de modèles, pour des tâches comme le débruitage d'images ou la vision par ordinateur par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(mnist_train), np.shape(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist_train est un data frame de taille 60000 $\\times$ 785. Les variables sont des variables quantitatives avec Y la vraie valeur du chiffre écrit et les variables X, sont des variables qui représentent les intensités des pixels (entre 0 et 1, 0 : noir, 1 : blanc). Chaque ligne représente donc une image en noir et blanc au format 28x28 pixels, ainsi que le chiffre manuscrit qui est représenté.\n",
    "\n",
    "De même mnist_test est un data frame de taille 10000 $\\times$ 785. On a donc environ 14% des valeurs qui sont dans le jeu test afin d'évaluer la qualité des modèles entrainés sur mnist_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthodes des k plus proches voisins\n",
    "\n",
    "Dans cette partie, on souhaite appliquer la méthode des k plus proches voisins . \\\n",
    "Ce modèle prédit la classe majoritaire pour les k proches voisins, c'est à dire:\n",
    "$\n",
    "\\hat{y} = \\arg\\max_{C} \\operatorname{card}\\left\\{ i \\mid Y_i = C,\\, X_i \\in N_k(x) \\right\\}\n",
    "$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Méthode des k plus proches voisins\n",
    "\n",
    "#on commence par centré et réduire les variables X\n",
    "scaler = StandardScaler()\n",
    "X_scaled_train = scaler.fit_transform(mnist_train.iloc[:,1:])\n",
    "X_scaled_test = scaler.fit_transform(mnist_test.iloc[:,1:])\n",
    "Y_train = mnist_train.iloc[:,0]\n",
    "Y_test = mnist_test.iloc[:,0]\n",
    "\n",
    "#On applique la méthode des K plus proches voisins avec une grille d'hyperparamètres\n",
    "param_grid = {'n_neighbors' : range(1,5)}\n",
    "models_knn = GridSearchCV(KNeighborsClassifier(), param_grid, n_jobs=-1).fit(X_scaled_train, Y_train)\n",
    "cv_results = pd.DataFrame(models_knn.cv_results_)\n",
    "cv_results.head()\n",
    "best_model_knn = models_knn.best_estimator_\n",
    "err_test_knn = mean_squared_error(best_model_knn.predict(X_scaled_test), Y_test)\n",
    "err_train_knn = mean_squared_error(best_model_knn.predict(X_scaled_test), Y_train)\n",
    "print(f\"L'erreur quadratique moyenne du modèle des plus proches voisins sur l'échantillon d'apprentissage est de {err_train_knn:.3f} et de {err_test_knn:.3f} sur l'échantillon test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des 9 premieres ligne sous forme d'image et label\n",
    "\n",
    "for i in range(9):\n",
    "    # Extraction de l'image\n",
    "    M = mnist_train.iloc[i, 1:].to_numpy().reshape((28, 28))\n",
    " \n",
    "    # Ajout du subplot\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(M, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.title(f\"Chiffre {mnist_train.iloc[i, 0]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de régression logistique\n",
    "\n",
    "On applique un modèle de régression logistique.\n",
    "Le modèle peut s'écrire :  \n",
    "$\\hat{y} = \\arg\\max_{C} \\mathbb{P}(Y = C \\mid X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modèles de régression logistique\n",
    "model_reg_log = LogisticRegression(max_iter = 100, solver = 'newton-cg')\n",
    "model_reg_log.fit(X_scaled_train, Y_train)\n",
    "x0 = X_scaled_test[0,:].reshape(1,-1)\n",
    "y0 = model_reg_log.predict(x0)\n",
    "print(f\"Le nombre prédit en x0 est y0 = {y0.item():.3f} or y = {Y_test[0]}\")\n",
    "y_pred_test = model_reg_log.predict(X_scaled_test)\n",
    "y_pred_train = model_reg_log.predict(X_scaled_train)\n",
    "err_test_log = mean_squared_error(y_pred_test, Y_test)\n",
    "err_train_log = mean_squared_error(y_pred_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"L'erreur quadratique moyenne du modèle de régression logistique sur l'échantillon d'apprentissage est de {err_train_log:.3f} et de {err_test_log:.3f} sur l'échantillon test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse discriminante linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(X_scaled_train, Y_train)\n",
    "print(f\"Le nombre prédit en x0 est Y0 = {LDA.predict(x0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Dans cette partie, nous appliquons la méthode ** Random Forest** à notre jeu de données MNIST. Ce modèle d’ensemble repose sur la combinaison de plusieurs arbres de décision, chacun étant entraîné sur un sous-échantillon des données et un sous-ensemble de variables.\n",
    "L'objectif est de contrôler le nombre de variables testées à chaque séparation dans les arbres. Ainsi , on pourra optimiser la diversité des arbres et éviter le surapprentissage.\n",
    "Nous utilisons GridSearchCV de scikit-learn pour tester différentes valeurs de max_features : 20,50,100...\n",
    "Nous combinons également cela avec une validation croisée à 5 plis sur l’échantillon d’apprentissage, ce qui permet d’évaluer la robustesse du modèle pour chaque valeur testée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chargement des données\n",
    "col_names = ['Y'] + [f'X{i}' for i in range(1, 785)]\n",
    "\n",
    "mnist_train = pd.read_csv(\"../data/mnist_train.csv\", sep=\",\", names=col_names, header=None)\n",
    "mnist_test = pd.read_csv(\"../data/mnist_test.csv\", sep=\",\", names=col_names, header=None)\n",
    "\n",
    "# Encodage des étiquettes\n",
    "mnist_train['Y'] = mnist_train['Y'].astype('category')\n",
    "mnist_test['Y'] = mnist_test['Y'].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Meilleur paramètre max_features : {'max_features': 50}\n",
      "Taux de bonne classification (Random Forest) : 0.9374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Données\n",
    "X_train = mnist_train.iloc[:, 1:].to_numpy()\n",
    "y_train = mnist_train['Y'].to_numpy()\n",
    "\n",
    "X_test = mnist_test.iloc[:, 1:].to_numpy()\n",
    "y_test = mnist_test['Y'].to_numpy()\n",
    "\n",
    "# Sous-échantillon pour réduire le temps de calcul\n",
    "X_small = X_train[:5000]\n",
    "y_small = y_train[:5000]\n",
    "\n",
    "# Grille d'hyperparamètres pour max_features\n",
    "param_grid = {\n",
    "    'max_features': [20, 50, 100, 200, 'sqrt']\n",
    "}\n",
    "\n",
    "# Modèle de base\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Validation croisée avec GridSearch (5-fold)\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=param_grid,\n",
    "                       cv=5,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=-1,\n",
    "                       verbose=1)\n",
    "\n",
    "# Entraînement sur le sous-échantillon\n",
    "grid_rf.fit(X_small, y_small)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_rf = grid_rf.best_estimator_\n",
    "print(\"Meilleur paramètre max_features :\", grid_rf.best_params_)\n",
    "\n",
    "# Prédictions sur les données de test complètes\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Évaluation de la performance\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Taux de bonne classification (Random Forest) : {accuracy_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "La méthode Random Forest, testée sur un sous-échantillon du jeu de données MNIST, s’est révélée particulièrement efficace pour la reconnaissance de chiffres manuscrits.\n",
    "L’optimisation de l’hyperparamètre max_features par validation croisée à 5 plis a permis d’obtenir de très bonnes performances, avec un taux de bonne classification de 93,74 % sur l’échantillon test.\n",
    "\n",
    "Cette robustesse s’explique par la capacité de Random Forest à combiner plusieurs arbres de décision, réduisant ainsi le surapprentissage tout en capturant la complexité des données visuelles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) à noyau gaussien\n",
    "\n",
    "Après avoir appliqué un modèle d’ensemble tel que la Random Forest, il est pertinent d’explorer une méthode complètement différente comme le **Support Vector Machine (SVM)**. Contrairement aux arbres de décision, le SVM repose sur une approche géométrique : il cherche à maximiser la marge entre les différentes classes dans un espace de représentation des données.\n",
    "\n",
    "Dans le cas du dataset MNIST, les classes ne sont pas toujours séparables linéairement. Nous utilisons donc ici un **noyau gaussien (ou RBF)**, qui permet au SVM de transformer les données dans un espace de plus grande dimension où une séparation devient possible. Ce choix est appuyé par les résultats expérimentaux présentés en cours ( Chapitre 4: Support Vector Machine, p.20) le SVM radial obtient une erreur test de 5.4 %, meilleure que celle du SVM linéaire (6.5 %) et très proche de la Random Forest (5.9 %). Cela montre sa capacité à bien généraliser sans surajustement.\n",
    "\n",
    "### Objectif :\n",
    "L’objectif est d’**optimiser le paramètre gamma** du noyau RBF. Ce paramètre contrôle l’influence d’un point d’entraînement donné :  \n",
    "- un **gamma élevé** produit un modèle plus complexe et potentiellement surajusté,  \n",
    "- un **gamma faible** donne un modèle plus lisse.\n",
    "\n",
    "Nous testons plusieurs valeurs ('1e-3', '1e-2', '1e-1', '1') à l’aide de GridSearchCV avec validation croisée à 5 plis, sur un **sous-échantillon de 5000 images** pour maîtriser le temps de calcul.\n",
    "\n",
    "### Méthodologie :\n",
    "- Utilisation de `SVC` avec noyau 'rbf' de sklearn.\n",
    "- Recherche du meilleur `gamma` avec GridSearchCV avec validation croisée à 5 plis.\n",
    "- Évaluation finale sur l’échantillon test.\n",
    "\n",
    "Cette approche permet de comparer un modèle **géométrique puissant** à un modèle **d’ensemble stochastique** comme la Random Forest. Leurs performances respectives seront ensuite visualisées dans une synthèse comparative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Meilleur paramètre gamma : {'gamma': 0.001}\n",
      "Taux de bonne classification (SVM) : 0.1135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Données (on suppose qu'elles ont déjà été chargées)\n",
    "# On réutilise les mêmes noms que pour Random Forest\n",
    "X_train = mnist_train.iloc[:, 1:].to_numpy()\n",
    "y_train = mnist_train['Y'].to_numpy()\n",
    "\n",
    "X_test = mnist_test.iloc[:, 1:].to_numpy()\n",
    "y_test = mnist_test['Y'].to_numpy()\n",
    "\n",
    "# Sous-échantillon pour le temps de calcul\n",
    "X_small = X_train[:5000]\n",
    "y_small = y_train[:5000]\n",
    "\n",
    "# Grille d’hyperparamètres pour gamma (noyau RBF = gaussien)\n",
    "param_grid = {\n",
    "    'gamma': [1e-3, 1e-2, 1e-1, 1]\n",
    "}\n",
    "\n",
    "# Modèle SVM avec noyau gaussien\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "# Validation croisée avec GridSearchCV\n",
    "grid_svm = GridSearchCV(estimator=svm,\n",
    "                        param_grid=param_grid,\n",
    "                        cv=5,\n",
    "                        scoring='accuracy',\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Entraînement sur le sous-échantillon\n",
    "grid_svm.fit(X_small, y_small)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_svm = grid_svm.best_estimator_\n",
    "print(\"Meilleur paramètre gamma :\", grid_svm.best_params_)\n",
    "\n",
    "# Prédictions sur l’échantillon test complet\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"Taux de bonne classification (SVM) : {accuracy_svm:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’application du SVM à noyau gaussien au dataset MNIST nous permet d’explorer une méthode géométrique, fondamentalement différente des arbres d’ensemble. \n",
    "Malgré l’optimisation du paramètre gamma par validation croisée, le modèle atteint une précision de seulement 11,35 % sur les données de test. Ce résultat relativement faible suggère que, dans le cadre d’un sous-échantillonnage à 5000 observations, le SVM n’a pas réussi à capter la complexité des chiffres manuscrits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir testé la Random Forest et le SVM, nous appliquons à présent l’algorithme XGBoost, une méthode d’ensemble basée sur le Gradient Boosting. XGBoost est particulièrement réputé pour sa performance et sa capacité à gérer efficacement de grands volumes de données.\n",
    "\n",
    "Contrairement à la Random Forest, XGBoost construit chaque arbre de manière séquentielle, en corrigeant les erreurs des arbres précédents. Cette approche permet un ajustement plus fin, au prix d’un temps de calcul plus important.\n",
    "\n",
    "Notre objectif :=sera d'optimiser deux hyperparamètres clés : max_depth : profondeur maximale des arbres et n_estimators : nombre total d’arbres.\n",
    "\n",
    "Nous avons utilisé GridSearchCV avec validation croisée à 5 plis sur un sous-échantillon de 5000 images pour maîtriser le temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afane\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:31:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres : {'max_depth': 5, 'n_estimators': 100}\n",
      "Taux de bonne classification (XGBoost) : 0.9381\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Données\n",
    "X_train = mnist_train.iloc[:, 1:].to_numpy()\n",
    "y_train = mnist_train['Y'].to_numpy()\n",
    "\n",
    "X_test = mnist_test.iloc[:, 1:].to_numpy()\n",
    "y_test = mnist_test['Y'].to_numpy()\n",
    "\n",
    "# Sous-échantillon pour maîtriser le temps de calcul\n",
    "X_small = X_train[:5000]\n",
    "y_small = y_train[:5000]\n",
    "\n",
    "# Grille d'hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100]\n",
    "}\n",
    "\n",
    "# Modèle de base\n",
    "xgb = XGBClassifier(\n",
    "    use_label_encoder=False,  # pour éviter les warnings\n",
    "    eval_metric='mlogloss',   # métrique multi-classe par défaut\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# GridSearchCV avec validation croisée 5 plis\n",
    "grid_xgb = GridSearchCV(estimator=xgb,\n",
    "                        param_grid=param_grid,\n",
    "                        cv=5,\n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        verbose=1)\n",
    "\n",
    "# Entraînement\n",
    "grid_xgb.fit(X_small, y_small)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "print(\"Meilleurs hyperparamètres :\", grid_xgb.best_params_)\n",
    "\n",
    "# Prédictions sur les données de test complètes\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"Taux de bonne classification (XGBoost) : {accuracy_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les meilleurs paramètres trouvés : max_depth = 5, n_estimators = 100.\n",
    "\n",
    "Taux de bonne classification sur le jeu test : 93,81 %.\n",
    "\n",
    "Ce résultat est comparable à celui obtenu avec la Random Forest, confirmant que les méthodes d’ensemble sont bien adaptées à des tâches complexes comme la classification des chiffres manuscrits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## à modifier en fonctiond  e la conclusion générale\n",
    "## Conclusion générale\n",
    "\n",
    "La comparaion des trois méthodes de classification supervisée sur un sous-échantillon du jeu de données MNIST (5000 images d'entraînement et 10 000 images de test).\n",
    "\n",
    "- **La Random Forest** a obtenu un excellent compromis entre performance (93,7 %) et temps de calcul.\n",
    "- **Le SVM à noyau gaussien**, bien que théoriquement puissant, a montré des performances faibles dans notre configuration (11,4 %), probablement à cause du faible échantillon et du manque d’ajustement fin.\n",
    "- **L’algorithme XGBoost**, très utilisé en pratique, a affiché les meilleurs résultats (93,8 %) tout en restant raisonnable en termes de calcul.\n",
    "\n",
    "Chaque méthode a ses avantages : les modèles d’ensemble comme XGBoost et la Random Forest sont efficaces sur ce type de données, tandis que les SVM nécessitent des ajustements plus fins et des ressources plus importantes.\n",
    "\n",
    "Notre analyse met en évidence l’importance de la validation croisée et de l’optimisation des hyperparamètres dans la réussite d’un modèle.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 969242,
     "sourceId": 1639397,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30028,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
